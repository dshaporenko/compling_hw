{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "punct = set(punctuation)\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances\n",
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = open('sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('correct_sents.txt', encoding='utf8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [sent.split() for sent in open('corpus_ng.txt', encoding='utf8').read().splitlines()]\n",
    "WORDS = Counter()\n",
    "for sent in corpus:\n",
    "    WORDS.update(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(WORDS.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "vec = TfidfVectorizer(analyzer='char', ngram_range=(1,1))\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_vec(text, X, vec, TOPN=3):\n",
    "    v = vec.transform([text])\n",
    "    similarities = cosine_distances(v, X)\n",
    "    topn = similarities.argsort()[0][:TOPN]\n",
    "    \n",
    "    return [id2word[top] for top in topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, metric=textdistance.levenshtein):\n",
    "    top = get_closest_match_vec(text, X, vec, 5)\n",
    "    \n",
    "    similarities = Counter()\n",
    "    for word in top:\n",
    "        similarities[word] = metric.normalized_similarity(text, word)\n",
    "    closest = similarities.most_common(1)[0][0]\n",
    "    return closest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'апофеоз'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match('апофиоз', X, vec, metric=textdistance.levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_1 if (set(token)-punct)]\n",
    "    tokens_2 = [re.sub('(^\\W+|\\W+$)', '', token) for token in tokens_2 if (set(token)-punct)]\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8304035157810628\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(len(true)):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    \n",
    "    for pair in word_pairs:\n",
    "        \n",
    "        predicted = get_closest_hybrid_match(pair[1], X, vec, metric=textdistance.levenshtein)\n",
    "        if predicted == pair[0]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistakes = []\n",
    "total = 0\n",
    "\n",
    "for i in range(len(true)):\n",
    "    \n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    \n",
    "    for pair in word_pairs:\n",
    "        if pair[0] != pair[1]:\n",
    "            mistakes.append(pair)\n",
    "        \n",
    "        total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('сегодня', 'седня', 'средняя'),\n",
       " ('вообще', 'вобще', 'вообще'),\n",
       " ('вообще', 'ваще', 'ваще'),\n",
       " ('естественно', 'естесственно', 'естественно'),\n",
       " ('хочется', 'хочеться', 'хочется'),\n",
       " ('кстати', 'кстате', 'остатке'),\n",
       " ('очень', 'ооочень', 'очень'),\n",
       " ('как-то', 'както', 'каток'),\n",
       " ('очень', 'оооочень', 'окончательно'),\n",
       " ('это', 'ето', 'ето'),\n",
       " ('ничего', 'ничо', 'ничто'),\n",
       " ('что-то', 'чтото', 'что'),\n",
       " ('периодически', 'переодически', 'периодически'),\n",
       " ('получается', 'получаеться', 'получаться'),\n",
       " ('насчет', 'нащет', 'нищета'),\n",
       " ('здесь', 'сдесь', 'садись'),\n",
       " ('можно', 'можна', 'монтаж'),\n",
       " ('девчонки', 'девченки', 'девчонки'),\n",
       " ('что', 'што', 'шт'),\n",
       " ('наконец-то', 'наконецто', 'наконец')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(wt[0], wt[1], get_closest_hybrid_match(wt[1], X, vec, metric=textdistance.levenshtein)) for wt, _ in Counter(mistakes).most_common(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('сегодня', 'седня'), 24),\n",
       " (('вообще', 'вобще'), 18),\n",
       " (('вообще', 'ваще'), 17),\n",
       " (('естественно', 'естесственно'), 17),\n",
       " (('хочется', 'хочеться'), 16),\n",
       " (('кстати', 'кстате'), 16),\n",
       " (('очень', 'ооочень'), 14),\n",
       " (('как-то', 'както'), 9),\n",
       " (('очень', 'оооочень'), 9),\n",
       " (('это', 'ето'), 9),\n",
       " (('ничего', 'ничо'), 9),\n",
       " (('что-то', 'чтото'), 7),\n",
       " (('периодически', 'переодически'), 7),\n",
       " (('получается', 'получаеться'), 6),\n",
       " (('насчет', 'нащет'), 6),\n",
       " (('здесь', 'сдесь'), 6),\n",
       " (('можно', 'можна'), 5),\n",
       " (('девчонки', 'девченки'), 5),\n",
       " (('что', 'што'), 5),\n",
       " (('наконец-то', 'наконецто'), 5)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(mistakes).most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'остатке'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match('кстате', X, vec, metric=textdistance.levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['текста',\n",
       " 'таскает',\n",
       " 'стекает',\n",
       " 'остатке',\n",
       " 'текст',\n",
       " 'статике',\n",
       " 'сектант',\n",
       " 'сетка',\n",
       " 'касте',\n",
       " 'истекает']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_match_vec('кстате', X, vec, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_with_metric(text, lookup, metric=textdistance.levenshtein):\n",
    "    similarities = Counter()\n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.normalized_similarity(text, word) \n",
    "    \n",
    "    return similarities.most_common(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.5 s, sys: 536 ms, total: 29 s\n",
      "Wall time: 28.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('кстати', 0.8333333333333334)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "get_closest_match_with_metric('кстате', WORDS, textdistance.levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
